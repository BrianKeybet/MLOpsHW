{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbfa1bd5",
   "metadata": {},
   "source": [
    "1.6 Homework\n",
    "\n",
    "The goal of this homework is to train a simple model for predicting the duration of a ride - similar to what we did in this module.\n",
    "Q1. Downloading the data\n",
    "\n",
    "We'll use the same NYC taxi dataset, but instead of \"Green Taxi Trip Records\", we'll use \"For-Hire Vehicle Trip Records\".\n",
    "\n",
    "Download the data for January and February 2021.\n",
    "\n",
    "Note that you need \"For-Hire Vehicle Trip Records\", not \"High Volume For-Hire Vehicle Trip Records\".\n",
    "\n",
    "Read the data for January. How many records are there?\n",
    "\n",
    "    1054112\n",
    "    1154112\n",
    "    1254112\n",
    "    1354112\n",
    "\n",
    "Q2. Computing duration\n",
    "\n",
    "Now let's compute the duration variable. It should contain the duration of a ride in minutes.\n",
    "\n",
    "What's the average trip duration in January?\n",
    "\n",
    "    15.16\n",
    "    19.16\n",
    "    24.16\n",
    "    29.16\n",
    "\n",
    "Data preparation\n",
    "\n",
    "Check the distribution of the duration variable. There are some outliers.\n",
    "\n",
    "Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "How many records did you drop?\n",
    "Q3. Missing values\n",
    "\n",
    "The features we'll use for our model are the pickup and dropoff location IDs.\n",
    "\n",
    "But they have a lot of missing values there. Let's replace them with \"-1\".\n",
    "\n",
    "What's the fractions of missing values for the pickup location ID? I.e. fraction of \"-1\"s after you filled the NAs.\n",
    "\n",
    "    53%\n",
    "    63%\n",
    "    73%\n",
    "    83%\n",
    "\n",
    "Q4. One-hot encoding\n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "    Turn the dataframe into a list of dictionaries\n",
    "    Fit a dictionary vectorizer\n",
    "    Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix? (The number of columns).\n",
    "\n",
    "    2\n",
    "    152\n",
    "    352\n",
    "    525\n",
    "    725\n",
    "\n",
    "Q5. Training a model\n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "    Train a plain linear regression model with default parameters\n",
    "    Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n",
    "\n",
    "    5.52\n",
    "    10.52\n",
    "    15.52\n",
    "    20.52\n",
    "\n",
    "Q6. Evaluating the model\n",
    "\n",
    "Now let's apply this model to the validation dataset (Feb 2021).\n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n",
    "    6.01\n",
    "    11.01\n",
    "    16.01\n",
    "    21.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2784de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c5ea278",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('./data/fhv_tripdata_2021-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be57f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_len = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cfb85d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration'] = df.dropOff_datetime - df.pickup_datetime\n",
    "df['duration'] = df.duration.dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20932c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.1672240937939"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duration.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2206a5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.duration >= 1) & (df.duration <= 60)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "810c06ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PUlocationID', 'DOlocationID']\n",
    "\n",
    "df[categorical] = df[categorical].fillna(-1).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "189c7efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical] = df[categorical].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "182b6ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dicts = df[categorical].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4ebc2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c014bdcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1109826, 525)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "308be6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df.duration.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c9d8918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dv.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff2bf37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82e6aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55d9546b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.528519107205765"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ef03652",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PUlocationID', 'DOlocationID']\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    \n",
    "    df['duration'] = df.dropOff_datetime - df.pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b381fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = read_data('./data/fhv_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f017be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dicts = df_val[categorical].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2c9b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c8f5d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7986f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = df_val.duration.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9ead64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.014283147378706"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred, squared=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
